{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quaterback Passer Rating Using Python & Machine Learning \n",
    "## This project uses an artificial neural network, Long Short Term Memory (LTSM) to forecast an NFL quarterback's passer rating."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect the data files and save them in the data directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! curl -o ../data/blah.bin https://raw.githubusercontent.com/opencv/opencv/master/data/haarcascades/blah.bin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute rating function\n",
    "##### The NFL passer rating formula ranges on a scale from 0 to 158.3 based on completion percentage, yards per attempt, touchdowns per attempt, and interceptions per attempt. Input your values below to calculate a rating:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "else {\n",
    "\t\tvar a = ((pass_cmp/pass_att) - 0.3) * 5;\n",
    "\t\ta = (a>2.375)?2.375:a;\n",
    "\t\ta = (a<0)?0:a;\n",
    "\t\tvar b = ((pass_yds/pass_att) - 3) * .25;\n",
    "\t\tb = (b>2.375)?2.375:b;\n",
    "\t\tb = (b<0)?0:b;\n",
    "\t\tvar c = (pass_td/pass_att) * 20;\n",
    "\t\tc = (c>2.375)?2.375:c;\n",
    "\t\tc = (c<0)?0:c;\n",
    "\t\tvar d = 2.375 - ((pass_int/pass_att) * 25);\n",
    "\t\td = (d>2.375)?2.375:d;\n",
    "\t\td = (d<0)?0:d;\n",
    "\t\tvar rating = (a+b+c+d)/6 * 100;\n",
    "\t\toutput = Math.round(rating*100, 2)/100;\n",
    "\n",
    "def comp_passer_rating(pass_att, pass_cmp, pass_int, pass_tds, pass_yds):\n",
    "    '''\n",
    "    Function to compute passer rating.\n",
    "    INPUTS:if faces detected, update face column from False to True\n",
    "    OUTPUT: passer rating = real number 0 to 158.3\n",
    "    '''\n",
    "    # validate boundarires\n",
    "    if pass_cmp > pass_att:\n",
    "        print('Passes complete {} exceed passing attempts {}'.format(pass_cmp, pass_att))\n",
    "        return 0\n",
    "    if pass_tds > pass_att:\n",
    "        print('Passing TDs {} exceed passing attempts {}'.format(pass_tds, pass_att))\n",
    "        return 0\n",
    "    if pass_tds > pass_cmp:\n",
    "        print('Passing TDs {} exceed pass completions {}'.format(pass_tds, pass_cmp))\n",
    "        return 0\n",
    "    if pass_int > pass_att:\n",
    "        print('Interceptions {} exceed passing attempts {}'.format(pass_int, pass_att))\n",
    "        return 0\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    classifier_full = CascadeClassifier(classifier)\n",
    "    img_gray = cv2.cvtColor(img_rgb, cv2.COLOR_BGR2GRAY)\n",
    "    bounding_boxes = classifier_full.detectMultiScale(img_gray, scaleFactor=1.3, minNeighbors=7, minSize=(224, 224))\n",
    "    box_list = []\n",
    "    for box in bounding_boxes:\n",
    "        box_list.append(box)\n",
    "    if len(box_list) < 1:\n",
    "        return 0\n",
    "    else:\n",
    "        # update face to True\n",
    "        draw_boxes(img_gray, box_list)\n",
    "        draw_boxes(img_rgb, box_list)\n",
    "        img_rgb = cv2.cvtColor(img_rgb, cv2.COLOR_BGR2RGB)\n",
    "        # write img to img_proc and/or save to os\n",
    "    return img_gray, img_rgb, roi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "## Loading and Sorting Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Renwming files as data fas the same filenames for each subject.  Prepending the folder name to the filename, as the foldername is the subject id.\n",
    "# # ONLY RUN ONCE!!!!!!!\n",
    "# for root, dirs, files in os.walk('../data/TD_RGB_E'):\n",
    "#     if not files:\n",
    "#         continue\n",
    "#     prefix = os.path.basename(root)\n",
    "#     for f in files:\n",
    "#         os.rename(os.path.join(root, f), os.path.join(root, \"{}_{}\".format(prefix, f)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONLY RUN ONCE\n",
    "# sort_images('../data/base') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = '' # image name\n",
    "file_path = '' # path to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process Images Directory for Feeding into the Model\n",
    "image_list = build_image_list('../data/TD_RGB_E')\n",
    "print(len(image_list), image_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # copy files to a singular folder\n",
    "# dest_base = '../data/base'\n",
    "# for ig in image_list:\n",
    "#     shutil.copy(ig, dest_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from PIL import Image\n",
    "\n",
    "# im = Image.open('temp.png')\n",
    "# data = np.array(im)\n",
    "# flattened = data.flatten()\n",
    "\n",
    "# print data.shape\n",
    "# print flattened.shape\n",
    "\n",
    "# (612, 812, 4)\n",
    "# (1987776,)\n",
    "\n",
    "# Alternately, instead of calling data.flatten(), you could call data.reshape(-1). -1 is used as a placeholder for \"figure out what the given dimension should be\".\n",
    "\n",
    "# flattened = data.T.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crop Images with OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image in images:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_face(img_rgb, classifier):\n",
    "    '''\n",
    "    1st classifier: HAAR classifier for face detection\n",
    "    read image from img_orig column\n",
    "    process face\n",
    "    if faces detected, update face column from False to True\n",
    "    draw box around face\n",
    "    write modified image to img_proc column\n",
    "    call detect_eyes\n",
    "    if no face detected, exit loop\n",
    "    '''\n",
    "    classifier_full = CascadeClassifier(classifier)\n",
    "    img_gray = cv2.cvtColor(img_rgb, cv2.COLOR_BGR2GRAY)\n",
    "    bounding_boxes = classifier_full.detectMultiScale(img_gray, scaleFactor=1.3, minNeighbors=7, minSize=(224, 224))\n",
    "    box_list = []\n",
    "    for box in bounding_boxes:\n",
    "        box_list.append(box)\n",
    "    if len(box_list) < 1:\n",
    "        return 0\n",
    "    else:\n",
    "        # update face to True\n",
    "        draw_boxes(img_gray, box_list)\n",
    "        draw_boxes(img_rgb, box_list)\n",
    "        img_rgb = cv2.cvtColor(img_rgb, cv2.COLOR_BGR2RGB)\n",
    "        # write img to img_proc and/or save to os\n",
    "    return img_gray, img_rgb, roi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set classifier\n",
    "classifier = '../src/haarcascade_frontalface_default.xml'\n",
    "# read the image\n",
    "img_rgb = X_train['img_orig']\n",
    "\n",
    "# detect face - with HAAR cascade\n",
    "img_gray, img_rgb, roi = detect_face(img_rgb, classifier)\n",
    "\n",
    "# scale down\n",
    "\n",
    "# return roi\n",
    "\n",
    "# call model for image - call fisherfaces\n",
    "\n",
    "# write processed image to dataframe\n",
    "\n",
    "# update flag in dataframe\n",
    "\n",
    "# choose next image\n",
    "\n",
    "# once complete, pueh changes to database\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emotion Detection with VGG16 Pretrained CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the data into labels (encoded) and images converted to a 224x224x3 numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions = ['commecicomm','happy','ugh','shocked','sunglasses']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dir = '../data/train'\n",
    "\n",
    "img_height = 224\n",
    "img_width = 224\n",
    "batch_size = 20\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "    validation_split=0.2) # set validation split\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False,\n",
    "    subset='training') # set as training data\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir, # same directory as training data\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False,\n",
    "    subset='validation') # set as validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator.classes\n",
    "#train_generator.classes = keras.utils.to_categorical(train_generator.classes, num_classes=5, dtype='int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit_generator(\n",
    "#     train_generator,\n",
    "#     steps_per_epoch = train_generator.samples // batch_size,\n",
    "#     validation_data = validation_generator, \n",
    "#     validation_steps = validation_generator.samples // batch_size,\n",
    "#     epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = next(train_generator)\n",
    "print('Input features shape', X.shape)\n",
    "print('Actual labels shape', y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = VGG16(include_top=False, weights='imagenet', input_shape=(224,224,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    base_model,\n",
    "    Flatten(),\n",
    "    Dense(units=4096,activation=\"relu\"),\n",
    "    Dense(units=4096,activation=\"relu\"),\n",
    "    Dense(units=5, activation=\"softmax\")\n",
    "]) #    GlobalAveragePooling2D(),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "opt = Adam(lr=0.0001)\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])  # sparce_categorical_crossentropy throws an error if usewd with OHE.  See tensoeflow documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "steps_per_epoch = train_generator.n // batch_size\n",
    "validation_steps = validation_generator.n // batch_size\n",
    "\n",
    "history = model.fit_generator(train_generator,\n",
    "                              steps_per_epoch = steps_per_epoch,\n",
    "                              epochs=epochs,\n",
    "                              workers=4,\n",
    "                              validation_data=validation_generator,\n",
    "                              validation_steps=validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.evaluate(X, y, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model and architecture to single file\n",
    "model.save(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "close_database(con)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred_class)\n",
    "\n",
    "tn = cm_2[0,0]\n",
    "fn = cm_2[0,1]\n",
    "fp = cm_2[1,0]\n",
    "tp = cm_2[1,1]\n",
    "\n",
    "accurracy = (tp + tn)/(tn+tp+fn+fp)\n",
    "\n",
    "precision = tp / (tp+fp)\n",
    "\n",
    "recall = tp / (tp + fn)\n",
    "f1_score = 2*precision*recall/(precision+recall)\n",
    "print('My model metrics were: Accurracy: {}, Precision: {}, Recall: {}, and F1: {}'.format(accurracy,precision,recall,f1_score))\n",
    "\n",
    "\n",
    "plt.matshow(cm)\n",
    "\n",
    "plt.colorbar()\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show();\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MVP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add webcam support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    ret, img = cap.read()\n",
    "    '''\n",
    "    lots of code here\n",
    "    \n",
    "    '''\n",
    "    cv2.imshow('img', img)\n",
    "    #Display camera feed until ESC key is pressed\n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    if k == 27:\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
